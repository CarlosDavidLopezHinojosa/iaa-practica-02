{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al aprendizaje automático: Práctica 2\n",
    "\n",
    "En esta práctica se desarrollaran distintas variaciones del algorimo de regresión linear múltiple y se comparara con la implementación de la libreria `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la implementación de la función de regresión lineal múltiple he decidido hacerlo como un todo en uno, donde podremos variar la regularización y las funciones de error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_regression(X: np.ndarray, y: np.ndarray, \n",
    "                      error_function: callable, regularization_derivative: callable, \n",
    "                      epsilon: float, lambda_reg: float, learning_rate: float, \n",
    "                      epochs: int, batch_size: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Realiza la regresión lineal múltiple con descenso de gradiente y regularización.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Matriz de características (normalizada y con bias).\n",
    "        y (np.ndarray): Vector de etiquetas.\n",
    "        error_function (callable): Función para calcular el error.\n",
    "        regularization_derivative (callable): Derivada de la función de regularización.\n",
    "        epsilon (float): Umbral de convergencia.\n",
    "        lambda_reg (float): Peso de la regularización.\n",
    "        learning_rate (float): Tasa de aprendizaje.\n",
    "        epochs (int): Número de épocas.\n",
    "        batch_size (float): Porcentaje del dataset usado en cada batch (0-1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Vector de parámetros ajustados (model).\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0 < batch_size <= 1, \"batch_size debe estar en el rango (0, 1]\"\n",
    "    assert X.shape[0] == y.shape[0], \"X e y deben tener la misma cantidad de muestras\"\n",
    "    \n",
    "\n",
    "    dataset_size, features_size = X.shape\n",
    "    batch = max(1, int(batch_size * dataset_size))  # Asegura al menos 1 muestra por batch\n",
    "    model = np.random.rand(features_size)  \n",
    "\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        indices = np.random.permutation(dataset_size)  # Barajar datos en cada época\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        for i in range(0, dataset_size, batch):\n",
    "            X_batch = X_shuffled[i:i + batch]\n",
    "            y_batch = y_shuffled[i:i + batch]\n",
    "\n",
    "            regression_error = X_batch @ model - y_batch # y_pred - y\n",
    "            gradient = X_batch.T @ regression_error + lambda_reg * regularization_derivative(model) # w_i = w_i * error + reg\n",
    "            model -= learning_rate * gradient  # Actualización de pesos\n",
    "        \n",
    "        loss = error_function(X, y, model)\n",
    "        if abs(prev_loss - loss) < epsilon:\n",
    "            break\n",
    "        prev_loss = loss\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a definir una función de predicción, que nos ayudará como abtracción en nuestra tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: np.ndarray, model: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Realiza la predicción de un conjunto de datos.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Matriz de características.\n",
    "        model (np.ndarray): Vector de parámetros ajustados.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Vector de etiquetas predichas.\n",
    "    \"\"\"\n",
    "    return X @ model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder realizar una correcta medición del progreso de nuestro modelo de regresión vamos a crear las dos funciones de error que hemos dado en clase.\n",
    "\n",
    "- Error medio cuadrático (_MSE_): $\\frac{1}{n} \\sum^n_{i=1}(y_i - \\hat y_i)^2$\n",
    "\n",
    "- Error medio absoluto (_MAE_): $\\frac{1}{n} \\sum^n_{i=1}\\mid y_i - \\hat y_i \\mid$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(X: np.ndarray, y: np.ndarray, model: np.ndarray) -> float:\n",
    "    return np.mean((X @ model - y) ** 2)\n",
    "\n",
    "def mae(X: np.ndarray, y: np.ndarray, model: np.ndarray) -> float:\n",
    "    return np.mean(np.abs(X @ model - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para regularizar usaremos las distintas normas dadas en clase:\n",
    "\n",
    "- Norma $L_1$: ${\\sum^n_{i=1} \\mid v_i \\mid}$\n",
    "\n",
    "- Norma $L_2$: $\\sqrt{\\sum^n_{i=1} v_i^2}$\n",
    "\n",
    "Para uilizar estas regulariazaciones en el gradiente descendente, usaremos las derivadas de estas normas.\n",
    "\n",
    "$$\\frac{\\partial}{\\partial L_1} = \\frac{\\partial}{\\partial v} {\\sum^n_{i=1} \\mid v_i \\mid}= \\sum^n_{i=1} signo(v_i)$$\n",
    "$$\\frac{\\partial}{\\partial L_2} = \\frac{\\partial}{\\partial v} {\\sum^n_{i=1} v_i^2} = \\sum^n_{i=1} 2 \\cdot v_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(model: np.ndarray) -> float: # Lasso\n",
    "    return np.sum(np.sign(model))\n",
    "\n",
    "def l2(model: np.ndarray) -> float: # Rigde\n",
    "    return np.sum(2 * model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer una prueba con los datos que nos vienen en el enunciado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 2],\n",
    "    [1, 3],\n",
    "    [2, 3],\n",
    "    [2, 4],\n",
    "    [3, 2],\n",
    "    [3, 5],\n",
    "    [4, 1]\n",
    "])\n",
    "\n",
    "y = np.array([1.03, -1.44, 4.53, 2.24, 13.27, 5.62, 21.53])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_function = np.random.choice([mse, mae])\n",
    "\n",
    "lasso = [error_function, l1]\n",
    "ridge = [error_function, l2]\n",
    "\n",
    "choice = np.random.choice([0, 1])\n",
    "\n",
    "print(f'Error tipo: {\"Lasso\" if choice == 0 else \"Ridge\"}')\n",
    "\n",
    "my_model = linear_regression(X, y, *[lasso, ridge][choice], 1e-6, 0.1, 0.01, 1000, 0.5)\n",
    "print(f'Error de nuestro modelo ({error_function.__name__.upper()}): {error_function(X, y, my_model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(X, my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a representar las predicciones de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y, predictions):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y, label='Valores reales', marker='o')\n",
    "    plt.plot(predictions, label='Predicciones', marker='x')\n",
    "    plt.xlabel('Índice')\n",
    "    plt.ylabel('Valor')\n",
    "    plt.title('Comparación de valores reales y predicciones')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a probar con la función implementada de la libreria `sklearn` y la compararemos con nuestro algoritmo sobre el conjunto de datos de diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "import sklearn.datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = ds.load_diabetes(return_X_y=True)\n",
    "\n",
    "# Creación del modelo y predicción de los datos (Mí algoritmo)\n",
    "error_function = np.random.choice([mse, mae])\n",
    "\n",
    "lasso = [error_function, l1]\n",
    "ridge = [error_function, l2]\n",
    "\n",
    "choice = np.random.choice([0, 1])\n",
    "\n",
    "my_diabetes_model = linear_regression(X, y, *[lasso, ridge][choice], 1e-7, 0.2, 0.1, 6000, 0.1)\n",
    "my_predictions = predict(X, my_diabetes_model)\n",
    "\n",
    "# Creación del modelo y predicción de los datos (Modelo de sklearn)\n",
    "\n",
    "sklearn_model = lm.LinearRegression()\n",
    "sklearn_model.fit(X, y)\n",
    "sklearn_predictions = sklearn_model.predict(X)\n",
    "\n",
    "print('Mis predicciones:')\n",
    "print('Mi Error: ', mse(X, y, my_diabetes_model))\n",
    "plot_predictions(y, my_predictions)\n",
    "\n",
    "print('Predicciones de sklearn:')\n",
    "print('Error de sklearn: ', mse(X, y, sklearn_model.coef_))\n",
    "plot_predictions(y, sklearn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos uso de los mismos algoritmos de sklearn pero con terminos de regulariazción $L_1$, $L_2$ y $ElasticNet$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = lm.Lasso(alpha=0.1)\n",
    "lasso_model.fit(X, y)\n",
    "lasso_predictions = lasso_model.predict(X)\n",
    "\n",
    "print('Predicciones de Lasso:')\n",
    "print(f'Error de Lasso: {mse(X, y, lasso_model.coef_)}')\n",
    "plot_predictions(y, lasso_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = lm.Ridge(alpha=0.1)\n",
    "ridge_model.fit(X, y)\n",
    "ridge_predictions = ridge_model.predict(X)\n",
    "\n",
    "print('Predicciones de Ridge:')\n",
    "print('Error de Ridge: ', mse(X, y, ridge_model.coef_))\n",
    "plot_predictions(y, ridge_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_model = lm.ElasticNet(alpha=0.005, l1_ratio=0.85)\n",
    "elastic_net_model.fit(X, y)\n",
    "elastic_net_predictions = elastic_net_model.predict(X)\n",
    "\n",
    "print('Predicciones de Elastic Net:')\n",
    "print('Error de Elastic Net: ', mse(X, y, elastic_net_model.coef_))\n",
    "plot_predictions(y, elastic_net_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
